{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPn4WS25DjKMNKo71X2Vnxi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ankit-rathi/Data-Engineering-with-AWS/blob/main/Try_S3_Bucket_Setup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install boto3 library\n",
        "!pip install boto3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flpe1tMNmt1Q",
        "outputId": "d19806d0-06bb-4f26-d2ce-e1af5d7b8d4d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting boto3\n",
            "  Downloading boto3-1.35.40-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting botocore<1.36.0,>=1.35.40 (from boto3)\n",
            "  Downloading botocore-1.35.40-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3)\n",
            "  Downloading s3transfer-0.10.3-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.40->boto3) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.40->boto3) (2.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.36.0,>=1.35.40->boto3) (1.16.0)\n",
            "Downloading boto3-1.35.40-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.1/139.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.35.40-py3-none-any.whl (12.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.10.3-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.6/82.6 kB\u001b[0m \u001b[31m936.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jmespath, botocore, s3transfer, boto3\n",
            "Successfully installed boto3-1.35.40 botocore-1.35.40 jmespath-1.0.1 s3transfer-0.10.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "project_path = '/content/drive/My Drive/Personal'\n",
        "os.chdir(project_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8k5V_1Fmk5i",
        "outputId": "d87ad06a-bbac-4cff-99ca-092787c3ecb8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rd6n8KTdmWrp",
        "outputId": "b7e6d928-6cdd-4ffe-fddd-933832459f95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bucket 'my-bucket-ar' created successfully.\n",
            "Versioning enabled on bucket 'my-bucket-ar'.\n",
            "File 'aws-rootkey.csv' uploaded successfully.\n",
            "Public access block disabled for bucket 'my-bucket-ar'.\n",
            "Bucket policy applied to 'my-bucket-ar' for public read access.\n",
            "Bucket 'my-bucket-ar' and its contents deleted successfully.\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import boto3\n",
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Load AWS credentials from CSV\n",
        "aws_keys_df = pd.read_csv('aws-rootkey.csv')\n",
        "\n",
        "AWS_ACCESS_KEY_ID = aws_keys_df['Access_key_ID'][0]\n",
        "AWS_SECRET_ACCESS_KEY = aws_keys_df['Secret_access_key'][0]\n",
        "REGION_NAME = aws_keys_df['Region'][0]\n",
        "\n",
        "# Initialize boto3 client\n",
        "s3_client = boto3.client(\n",
        "    's3',\n",
        "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
        "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
        "    region_name=REGION_NAME\n",
        ")\n",
        "\n",
        "s3_resource = boto3.resource(\n",
        "    's3',\n",
        "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
        "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
        "    region_name=REGION_NAME\n",
        ")\n",
        "\n",
        "# Define bucket name\n",
        "bucket_name = 'my-bucket-ar'\n",
        "\n",
        "# Step 1: Create S3 Bucket\n",
        "def create_s3_bucket(bucket_name):\n",
        "    try:\n",
        "        response = s3_client.create_bucket(\n",
        "            Bucket=bucket_name,\n",
        "            CreateBucketConfiguration={'LocationConstraint': REGION_NAME}\n",
        "        )\n",
        "        print(f\"Bucket '{bucket_name}' created successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating bucket: {str(e)}\")\n",
        "\n",
        "# Step 2: Enable versioning for the bucket\n",
        "def enable_versioning(bucket_name):\n",
        "    try:\n",
        "        versioning = s3_client.put_bucket_versioning(\n",
        "            Bucket=bucket_name,\n",
        "            VersioningConfiguration={'Status': 'Enabled'}\n",
        "        )\n",
        "        print(f\"Versioning enabled on bucket '{bucket_name}'.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error enabling versioning: {str(e)}\")\n",
        "\n",
        "# Step 3: Upload files (CSV and JSON) to the bucket\n",
        "def upload_files_to_s3(bucket_name, files):\n",
        "    try:\n",
        "        for file in files:\n",
        "            file_name = os.path.basename(file)\n",
        "            s3_client.upload_file(file, bucket_name, file_name)\n",
        "            print(f\"File '{file_name}' uploaded successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error uploading files: {str(e)}\")\n",
        "\n",
        "# Step 4a: Disable block public access for the bucket\n",
        "def disable_block_public_access(bucket_name):\n",
        "    try:\n",
        "        s3_client.put_public_access_block(\n",
        "            Bucket=bucket_name,\n",
        "            PublicAccessBlockConfiguration={\n",
        "                'BlockPublicAcls': False,\n",
        "                'IgnorePublicAcls': False,\n",
        "                'BlockPublicPolicy': False,\n",
        "                'RestrictPublicBuckets': False\n",
        "            }\n",
        "        )\n",
        "        print(f\"Public access block disabled for bucket '{bucket_name}'.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error disabling public access block: {str(e)}\")\n",
        "\n",
        "# Step 4b: Set bucket policy for public read access (Example)\n",
        "def set_bucket_policy(bucket_name):\n",
        "    bucket_policy = {\n",
        "        \"Version\": \"2012-10-17\",\n",
        "        \"Statement\": [\n",
        "            {\n",
        "                \"Effect\": \"Allow\",\n",
        "                \"Principal\": \"*\",\n",
        "                \"Action\": \"s3:GetObject\",\n",
        "                \"Resource\": f\"arn:aws:s3:::{bucket_name}/*\"\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # Convert the policy to JSON format\n",
        "    bucket_policy_json = json.dumps(bucket_policy)\n",
        "\n",
        "    try:\n",
        "        s3_client.put_bucket_policy(Bucket=bucket_name, Policy=bucket_policy_json)\n",
        "        print(f\"Bucket policy applied to '{bucket_name}' for public read access.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error setting bucket policy: {str(e)}\")\n",
        "\n",
        "# Step 5: Delete all versions of objects and then delete the S3 bucket (Cleanup)\n",
        "def cleanup_s3_bucket(bucket_name):\n",
        "    try:\n",
        "        bucket = s3_resource.Bucket(bucket_name)\n",
        "\n",
        "        # Delete all versions of objects\n",
        "        bucket.object_versions.delete()\n",
        "\n",
        "        # Delete the bucket itself\n",
        "        s3_client.delete_bucket(Bucket=bucket_name)\n",
        "        print(f\"Bucket '{bucket_name}' and its contents deleted successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error cleaning up bucket: {str(e)}\")\n",
        "\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Define some local files to upload\n",
        "    csv_file = '/content/drive/My Drive/Personal/aws-rootkey.csv'  # Change path accordingly\n",
        "    #json_file = '/content/drive/My Drive/Personal/sample.json'  # Change path accordingly\n",
        "    files_to_upload = [csv_file] #, json_file]\n",
        "\n",
        "    # Step 1: Create the S3 bucket\n",
        "    create_s3_bucket(bucket_name)\n",
        "\n",
        "    # Step 2: Enable versioning for the bucket\n",
        "    enable_versioning(bucket_name)\n",
        "\n",
        "    # Step 3: Upload files to the S3 bucket\n",
        "    upload_files_to_s3(bucket_name, files_to_upload)\n",
        "\n",
        "    # Step 4a: Disable block public access for the bucket\n",
        "    disable_block_public_access(bucket_name)\n",
        "\n",
        "    # Step 4b: Set public read access bucket policy\n",
        "    set_bucket_policy(bucket_name)\n",
        "\n",
        "    # Uncomment the following line if you want to clean up the resources after testing:\n",
        "    cleanup_s3_bucket(bucket_name)\n",
        ""
      ]
    }
  ]
}