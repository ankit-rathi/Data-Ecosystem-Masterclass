{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6qNx9H7hDLjWb5URmQFsK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ankit-rathi/Data-Engineering-with-AWS/blob/main/Try_Kinesis_Stream.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install boto3 library\n",
        "!pip install boto3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flpe1tMNmt1Q",
        "outputId": "d19806d0-06bb-4f26-d2ce-e1af5d7b8d4d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting boto3\n",
            "  Downloading boto3-1.35.40-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting botocore<1.36.0,>=1.35.40 (from boto3)\n",
            "  Downloading botocore-1.35.40-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3)\n",
            "  Downloading s3transfer-0.10.3-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.40->boto3) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.40->boto3) (2.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.36.0,>=1.35.40->boto3) (1.16.0)\n",
            "Downloading boto3-1.35.40-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.1/139.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.35.40-py3-none-any.whl (12.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.10.3-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.6/82.6 kB\u001b[0m \u001b[31m936.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jmespath, botocore, s3transfer, boto3\n",
            "Successfully installed boto3-1.35.40 botocore-1.35.40 jmespath-1.0.1 s3transfer-0.10.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "project_path = '/content/drive/My Drive/Personal'\n",
        "os.chdir(project_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8k5V_1Fmk5i",
        "outputId": "d87ad06a-bbac-4cff-99ca-092787c3ecb8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rd6n8KTdmWrp",
        "outputId": "9767a0c3-514e-4664-aa31-af73bdc6fdd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S3 bucket 'kinesis-logging-bucket-1728974563' created successfully.\n",
            "Error creating Kinesis stream: An error occurred (ResourceInUseException) when calling the CreateStream operation: Stream my-kinesis-stream under account 419441991443 already exists.\n",
            "Record {'id': 1, 'message': 'Hello, this is record 1.'} pushed to Kinesis.\n",
            "Record {'id': 2, 'message': 'Hello, this is record 2.'} pushed to Kinesis.\n",
            "Record {'id': 3, 'message': 'Hello, this is record 3.'} pushed to Kinesis.\n",
            "Logged 6 records to S3 bucket 'kinesis-logging-bucket-1728974563'.\n",
            "Kinesis stream 'my-kinesis-stream' deleted successfully.\n",
            "S3 bucket 'kinesis-logging-bucket-1728974563' deleted successfully.\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import os\n",
        "import boto3\n",
        "import json\n",
        "import time\n",
        "from botocore.exceptions import ClientError\n",
        "\n",
        "# Load AWS credentials from CSV\n",
        "aws_keys_df = pd.read_csv('aws-rootkey.csv')\n",
        "\n",
        "AWS_ACCESS_KEY_ID = aws_keys_df['Access_key_ID'][0]\n",
        "AWS_SECRET_ACCESS_KEY = aws_keys_df['Secret_access_key'][0]\n",
        "REGION_NAME = aws_keys_df['Region'][0]\n",
        "\n",
        "# Initialize boto3 clients\n",
        "s3_client = boto3.client('s3', region_name=REGION_NAME,\n",
        "                         aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
        "                         aws_secret_access_key=AWS_SECRET_ACCESS_KEY)\n",
        "\n",
        "kinesis_client = boto3.client('kinesis', region_name=REGION_NAME,\n",
        "                              aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
        "                              aws_secret_access_key=AWS_SECRET_ACCESS_KEY)\n",
        "\n",
        "s3_resource = boto3.resource('s3', region_name=REGION_NAME,\n",
        "                             aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
        "                             aws_secret_access_key=AWS_SECRET_ACCESS_KEY)\n",
        "\n",
        "\n",
        "# Step 1: Create an S3 bucket for logging\n",
        "def create_s3_bucket(bucket_name):\n",
        "    try:\n",
        "        s3_client.create_bucket(\n",
        "            Bucket=bucket_name,\n",
        "            CreateBucketConfiguration={'LocationConstraint': REGION_NAME}\n",
        "        )\n",
        "        print(f\"S3 bucket '{bucket_name}' created successfully.\")\n",
        "    except ClientError as e:\n",
        "        print(f\"Error creating S3 bucket: {e}\")\n",
        "\n",
        "# Step 2: Create a Kinesis Data Stream\n",
        "def create_kinesis_stream(stream_name, shard_count=1):\n",
        "    try:\n",
        "        kinesis_client.create_stream(\n",
        "            StreamName=stream_name,\n",
        "            ShardCount=shard_count\n",
        "        )\n",
        "        print(f\"Kinesis stream '{stream_name}' created successfully.\")\n",
        "\n",
        "        # Wait for the stream to become active\n",
        "        while True:\n",
        "            response = kinesis_client.describe_stream(StreamName=stream_name)\n",
        "            status = response['StreamDescription']['StreamStatus']\n",
        "            if status == 'ACTIVE':\n",
        "                print(f\"Kinesis stream '{stream_name}' is active.\")\n",
        "                break\n",
        "            time.sleep(2)\n",
        "    except ClientError as e:\n",
        "        print(f\"Error creating Kinesis stream: {e}\")\n",
        "\n",
        "# Step 3: Push data to Kinesis stream\n",
        "def put_records_to_kinesis(stream_name, records):\n",
        "    for record in records:\n",
        "        try:\n",
        "            kinesis_client.put_record(\n",
        "                StreamName=stream_name,\n",
        "                Data=json.dumps(record),\n",
        "                PartitionKey=\"partitionkey\"\n",
        "            )\n",
        "            print(f\"Record {record} pushed to Kinesis.\")\n",
        "        except ClientError as e:\n",
        "            print(f\"Error pushing record to Kinesis: {e}\")\n",
        "\n",
        "# Step 4: Log streaming data to S3\n",
        "def log_kinesis_to_s3(stream_name, bucket_name, log_file):\n",
        "    try:\n",
        "        shard_iterator_response = kinesis_client.get_shard_iterator(\n",
        "            StreamName=stream_name,\n",
        "            ShardId='shardId-000000000000',  # Default shard ID\n",
        "            ShardIteratorType='TRIM_HORIZON'\n",
        "        )\n",
        "        shard_iterator = shard_iterator_response['ShardIterator']\n",
        "\n",
        "        # Get records from the stream\n",
        "        response = kinesis_client.get_records(ShardIterator=shard_iterator, Limit=10)\n",
        "        records = response['Records']\n",
        "\n",
        "        if records:\n",
        "            # Log records to S3 as a JSON file\n",
        "            log_data = [json.loads(record['Data']) for record in records]\n",
        "            s3_client.put_object(\n",
        "                Bucket=bucket_name,\n",
        "                Key=log_file,\n",
        "                Body=json.dumps(log_data),\n",
        "                ContentType='application/json'\n",
        "            )\n",
        "            print(f\"Logged {len(records)} records to S3 bucket '{bucket_name}'.\")\n",
        "        else:\n",
        "            print(\"No records to log.\")\n",
        "    except ClientError as e:\n",
        "        print(f\"Error logging Kinesis data to S3: {e}\")\n",
        "\n",
        "# Step 5: Cleanup - Delete Kinesis stream and S3 bucket\n",
        "def cleanup_resources(stream_name, bucket_name):\n",
        "    try:\n",
        "        # Delete Kinesis stream\n",
        "        kinesis_client.delete_stream(StreamName=stream_name, EnforceConsumerDeletion=True)\n",
        "        print(f\"Kinesis stream '{stream_name}' deleted successfully.\")\n",
        "\n",
        "        # Delete all objects in the S3 bucket\n",
        "        bucket = s3_resource.Bucket(bucket_name)\n",
        "        bucket.objects.all().delete()\n",
        "\n",
        "        # Delete the S3 bucket\n",
        "        s3_client.delete_bucket(Bucket=bucket_name)\n",
        "        print(f\"S3 bucket '{bucket_name}' deleted successfully.\")\n",
        "    except ClientError as e:\n",
        "        print(f\"Error cleaning up resources: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Define parameters\n",
        "    bucket_name = 'kinesis-logging-bucket-' + str(int(time.time()))  # Make bucket name unique\n",
        "    stream_name = 'my-kinesis-stream'\n",
        "    log_file = 'kinesis-log.json'\n",
        "\n",
        "    # Sample records to push to Kinesis\n",
        "    records_to_push = [\n",
        "        {\"id\": 1, \"message\": \"Hello, this is record 1.\"},\n",
        "        {\"id\": 2, \"message\": \"Hello, this is record 2.\"},\n",
        "        {\"id\": 3, \"message\": \"Hello, this is record 3.\"}\n",
        "    ]\n",
        "\n",
        "    # Step 1: Create an S3 bucket\n",
        "    create_s3_bucket(bucket_name)\n",
        "\n",
        "    # Step 2: Create a Kinesis Data Stream\n",
        "    create_kinesis_stream(stream_name)\n",
        "\n",
        "    # Step 3: Push records to Kinesis\n",
        "    put_records_to_kinesis(stream_name, records_to_push)\n",
        "\n",
        "    # Step 4: Log Kinesis records to S3\n",
        "    log_kinesis_to_s3(stream_name, bucket_name, log_file)\n",
        "\n",
        "    # Step 5: Cleanup resources after testing\n",
        "    cleanup_resources(stream_name, bucket_name)\n"
      ]
    }
  ]
}